@article{acemoglu2011bayesian,
  title={Bayesian learning in social networks},
  author={Acemoglu, Daron and Dahleh, Munther A and Lobel, Ilan and Ozdaglar, Asuman},
  journal={The Review of Economic Studies},
  volume={78},
  number={4},
  pages={1201--1236},
  year={2011},
  publisher={Oxford University Press}
}

@article{albrecht2018autonomous,
  title={Autonomous agents modelling other agents: A comprehensive survey and open problems},
  author={Albrecht, Stefano V and Stone, Peter},
  journal={Artificial Intelligence},
  volume={258},
  pages={66--95},
  year={2018},
  publisher={Elsevier}
}

@article{alshedivat2018continuous,
  title={Continuous adaptation via meta-learning in nonstationary and competitive environments},
  author={Al-Shedivat, Maruan and Bansal, Trapit and Burda, Yuri and Sutskever, Ilya and Mordatch, Igor and Abbeel, Pieter},
  journal={Proceedings of the 6th International Conference on Learning Representations},
  year={2018}
}

@article{athey2013position,
  title={Position auctions with consumer search},
  author={Athey, Susan and Ellison, Glenn},
  journal={The Quarterly Journal of Economics},
  volume={126},
  number={3},
  pages={1213--1270},
  year={2011},
  publisher={Oxford University Press}
}


@article{balduzzi2018mechanics,
  title={The mechanics of n-player differentiable games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  journal={Proceedings of the 35th International Conference on Machine Learning},
  pages={354--363},
  year={2018},
  organization={PMLR}
}

@article{banerjee1992simple,
  title={A simple model of herd behavior},
  author={Banerjee, Abhijit V},
  journal={The Quarterly Journal of Economics},
  volume={107},
  number={3},
  pages={797--817},
  year={1992},
  publisher={Oxford University Press}
}

@article{bergemann2002information,
  title={Information and mechanism design},
  author={Bergemann, Dirk and V{\"a}lim{\"a}ki, Juuso},
  journal={Journal of the European Economic Association},
  volume={3},
  number={2-3},
  pages={146--155},
  year={2005},
  publisher={Wiley Online Library}
}

@article{bernstein2002complexity,
  title={The complexity of decentralized control of Markov decision processes},
  author={Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
  journal={Mathematics of Operations Research},
  volume={27},
  number={4},
  pages={819--840},
  year={2002},
  publisher={INFORMS}
}

@article{bikhchandani1992theory,
  title={A theory of fads, fashion, custom, and cultural change as informational cascades},
  author={Bikhchandani, Sushil and Hirshleifer, David and Welch, Ivo},
  journal={Journal of Political Economy},
  volume={100},
  number={5},
  pages={992--1026},
  year={1992},
  publisher={University of Chicago Press}
}

@article{bolton1999strategic,
  title={Strategic experimentation},
  author={Bolton, Patrick and Harris, Christopher},
  journal={Econometrica},
  volume={67},
  number={2},
  pages={349--374},
  year={1999},
  publisher={Wiley Online Library}
}

@article{bowling2002multiagent,
  title={Multiagent learning using a variable learning rate},
  author={Bowling, Michael and Veloso, Manuela},
  journal={Artificial Intelligence},
  volume={136},
  number={2},
  pages={215--250},
  year={2002},
  publisher={Elsevier}
}

@article{bowling2005convergence,
  title={Convergence and no-regret in multiagent learning},
  author={Bowling, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={17},
  year={2005}
}

@article{brandl2024,
  title={The Social Learning Barrier},
  author={Brandl, Florian},
  journal={Working Paper},
  year={2024}
}

@article{busoniu2010multi,
  title={Multi-agent reinforcement learning: An overview},
  author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
  journal={Innovations in Multi-Agent Systems and Applications-1},
  pages={183--221},
  year={2010},
  publisher={Springer}
}

@book{chamley2004rational,
  title={Rational herds: Economic models of social learning},
  author={Chamley, Christophe},
  year={2004},
  publisher={Cambridge University Press}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing},
  pages={1724--1734},
  year={2014}
}

@article{crawford2007level,
  title={Level-k auctions: Can a nonequilibrium model of strategic thinking explain the winner's curse and overbidding in private-value auctions?},
  author={Crawford, Vincent P and Iriberri, Nagore},
  journal={Econometrica},
  volume={75},
  number={6},
  pages={1721--1770},
  year={2007},
  publisher={Wiley Online Library}
}

@article{degroot1974reaching,
  title={Reaching a consensus},
  author={DeGroot, Morris H},
  journal={Journal of the American Statistical Association},
  volume={69},
  number={345},
  pages={118--121},
  year={1974},
  publisher={Taylor \& Francis}
}

@article{enke2019correlation,
  title={Correlation neglect in belief formation},
  author={Enke, Benjamin and Zimmermann, Florian},
  journal={The Review of Economic Studies},
  volume={86},
  number={1},
  pages={313--332},
  year={2019},
  publisher={Oxford University Press}
}

@article{erev1998predicting,
  title={Predicting how people play games: Reinforcement learning in experimental games with unique, mixed strategy equilibria},
  author={Erev, Ido and Roth, Alvin E},
  journal={American Economic Review},
  pages={848--881},
  year={1998},
  publisher={JSTOR}
}

@article{eyster2010naive,
  title={Naive herding in rich-information settings},
  author={Eyster, Erik and Rabin, Matthew},
  journal={American Economic Journal: Microeconomics},
  volume={2},
  number={4},
  pages={221--243},
  year={2010},
  publisher={American Economic Association}
}

@article{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  journal={Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{gale1996we,
  title={What we do and do not know about the rate of learning},
  author={Gale, Douglas},
  journal={Mimeo, New York University},
  year={1996}
}

@article{gale2003bayesian,
  title={Bayesian learning in social networks},
  author={Gale, Douglas and Kariv, Shachar},
  journal={Games and Economic Behavior},
  volume={45},
  number={2},
  pages={329--346},
  year={2003},
  publisher={Elsevier}
}

@article{golub2010naive,
  title={Naive learning in social networks and the wisdom of crowds},
  author={Golub, Benjamin and Jackson, Matthew O},
  journal={American Economic Journal: Microeconomics},
  volume={2},
  number={1},
  pages={112--149},
  year={2010},
  publisher={American Economic Association}
}

@article{golub2017learning,
  title={Learning in social networks},
  author={Golub, Benjamin and Sadler, Evan},
  journal={The Oxford Handbook of the Economics of Networks},
  year={2017},
  publisher={Oxford University Press}
}

@article{guarino2011wise,
  title={Wise crowds or wise minorities?},
  author={Guarino, Antonio and Harmgart, Heike and Huck, Steffen},
  journal={Theory and Decision},
  volume={72},
  number={3},
  pages={385--407},
  year={2011},
  publisher={Springer}
}

@article{hansen2004dynamic,
  title={Dynamic programming for partially observable stochastic games},
  author={Hansen, Eric A and Bernstein, Daniel S and Zilberstein, Shlomo},
  journal={Proceedings of the 19th National Conference on Artificial Intelligence},
  pages={709--715},
  year={2004},
  organization={AAAI Press}
}

@article{harel2021rational,
  title={Rational groupthink},
  author={Harel, Matan and Mossel, Elchanan and Strack, Philipp and Tamuz, Omer},
  journal={The Quarterly Journal of Economics},
  volume={136},
  number={1},
  pages={621--668},
  year={2021},
  publisher={Oxford University Press}
}

@article{he2016opponent,
  title={Opponent modeling in deep reinforcement learning},
  author={He, He and Boyd-Graber, Jordan and Kwok, Kevin and Daum{\'e} III, Hal},
  journal={Proceedings of the 33rd International Conference on Machine Learning},
  pages={1804--1813},
  year={2016},
  organization={PMLR}
}

@article{hernandez2017survey,
  title={A survey of learning in multiagent environments: Dealing with non-stationarity},
  author={Hernandez-Leal, Pablo and Kaisers, Michael and Baarslag, Tim and de Cote, Enrique Munoz},
  journal={arXiv preprint arXiv:1707.09183},
  year={2017}
}

@article{hu2003nash,
  title={Nash Q-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of Machine Learning Research},
  volume={4},
  pages={1039--1069},
  year={2003}
}

@article{huang2024learning,
  title={Learning in networks: Social learning, multi-agent learning and diffusion of information},
  author={Huang, Alex and Strack, Philipp and Tamuz, Omer},
  journal={Annual Review of Economics},
  volume={16},
  pages={1--28},
  year={2024},
  publisher={Annual Reviews}
}

@article{hurwicz1973design,
  title={The design of mechanisms for resource allocation},
  author={Hurwicz, Leonid},
  journal={The American Economic Review},
  volume={63},
  number={2},
  pages={1--30},
  year={1973},
  publisher={American Economic Association}
}

@article{jadbabaie2012non,
  title={Non-Bayesian social learning},
  author={Jadbabaie, Ali and Molavi, Pooya and Sandroni, Alvaro and Tahbaz-Salehi, Alireza},
  journal={Games and Economic Behavior},
  volume={76},
  number={1},
  pages={210--225},
  year={2012},
  publisher={Elsevier}
}

@article{jaderberg2019human,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{kaelbling1998planning,
  title={Planning and acting in partially observable stochastic domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial Intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}

@article{kahneman1973availability,
  title={Availability: A heuristic for judging frequency and probability},
  author={Kahneman, Daniel and Tversky, Amos},
  journal={Cognitive Psychology},
  volume={5},
  number={2},
  pages={207--232},
  year={1973},
  publisher={Elsevier}
}

@article{keller2005strategic,
  title={Strategic experimentation with exponential bandits},
  author={Keller, Godfrey and Rady, Sven and Cripps, Martin},
  journal={Econometrica},
  volume={73},
  number={1},
  pages={39--68},
  year={2005},
  publisher={Wiley Online Library}
}

@article{kim2021policy,
  title={Policy-aware model learning for policy gradient methods},
  author={Kim, Kyungjae and Seo, Younggyo and Song, Hyunwoo and Parisotto, Emilio and Song, Jinwoo and Lee, Sungik and Yang, Yung Yi},
  journal={arXiv preprint arXiv:2106.04051},
  year={2021}
}

@article{kim2022influencing,
  title={Influencing Long-Term Behavior in Multiagent Reinforcement Learning},
  author={Kim, Dong Ki and Yuan, Liu and Gong, Xuejiao and Ullman, Tomer D and Spelke, Elizabeth and Tenenbaum, Joshua B and Chuang, Ian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={41417--41432},
  year={2022}
}

@article{lauer2000algorithm,
  title={An algorithm for distributed reinforcement learning in cooperative multi-agent systems},
  author={Lauer, Martin and Riedmiller, Martin},
  journal={Proceedings of the 17th International Conference on Machine Learning},
  pages={535--542},
  year={2000},
  publisher={Morgan Kaufmann}
}

@article{laurent2011world,
author = {Guillaume J. Laurent and Laëtitia Matignon and N. Le Fort-Piat},
title ={The world of independent learners is not markovian},

journal = {International Journal of Knowledge-Based and Intelligent Engineering Systems},
volume = {15},
number = {1},
pages = {55-64},
year = {2011},
doi = {10.3233/KES-2010-0206},
}

@article{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  journal={Proceedings of the 11th International Conference on Machine Learning},
  pages={157--163},
  year={1994},
  publisher={Morgan Kaufmann}
}

@article{littman2001friend,
  title={Friend-or-foe Q-learning in general-sum games},
  author={Littman, Michael L},
  journal={Proceedings of the 18th International Conference on Machine Learning},
  pages={322--328},
  year={2001},
  publisher={Morgan Kaufmann}
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{migrow2022strategic,
  title={Strategic information revelation in simple games},
  author={Migrow, Dmitry},
  journal={Journal of Economic Theory},
  volume={200},
  pages={105379},
  year={2022},
  publisher={Elsevier}
}

@article{molavi2018theory,
  title={A theory of non-Bayesian social learning},
  author={Molavi, Pooya and Tahbaz-Salehi, Alireza and Jadbabaie, Ali},
  journal={Econometrica},
  volume={86},
  number={2},
  pages={445--490},
  year={2018},
  publisher={Wiley Online Library}
}

@article{monte2014bounded,
  title={Bounded memory and permanent reputations},
  author={Monte, Daniel},
  journal={Journal of Mathematical Economics},
  volume={54},
  pages={1--14},
  year={2014},
  publisher={Elsevier}
}

@article{mossel2015strategic,
  title={Strategic learning and the topology of social networks},
  author={Mossel, Elchanan and Sly, Allan and Tamuz, Omer},
  journal={Econometrica},
  volume={83},
  number={5},
  pages={1755--1794},
  year={2015},
  publisher={Wiley Online Library}
}

@article{mueller2013general,
author = {Mueller-Frank, Manuel},
title = {A general framework for rational learning in social networks},
journal = {Theoretical Economics},
volume = {8},
number = {1},
pages = {1-40},
keywords = {Learning, social networks, common knowledge, consensus, speed of convergence, optimal information aggregation, D82, D83, D85},
doi = {https://doi.org/10.3982/TE1015},
url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/TE1015},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.3982/TE1015},
abstract = {This paper provides a formal characterization of the process of rational learning in social networks. Agents receive initial private information and select an action out of a choice set under uncertainty in each of infinitely many periods, observing the history of choices of their neighbors. Choices are made based on a common behavioral rule. Conditions under which rational learning leads to global consensus, local indifference, and local disagreement are characterized. In the general setting considered, rational learning can lead to pairs of neighbors selecting different actions once learning ends while not being indifferent among their choices. The effect of the network structure on the degree of information aggregation and speed of convergence is also considered, and an answer to the question of optimal information aggregation in networks is provided. The results highlight distinguishing features between properties of Bayesian and non-Bayesian learning in social networks.},
year = {2013}
}


@article{myerson1981optimal,
  title={Optimal auction design},
  author={Myerson, Roger B},
  journal={Mathematics of Operations Research},
  volume={6},
  number={1},
  pages={58--73},
  year={1981},
  publisher={INFORMS}
}

@article{nekipelov2015econometrics,
  title={Econometrics for learning agents},
  author={Nekipelov, Denis and Syrgkanis, Vasilis and Tardos, Eva},
  journal={Proceedings of the Sixteenth ACM Conference on Economics and Computation},
  pages={1--18},
  year={2015},
  organization={ACM}
}

@article{nowé2012game,
  title={Game theory and multi-agent reinforcement learning},
  author={Now{\'e}, Ann and Vrancx, Peter and De Hauwere, Yann-Micha{\"e}l},
  journal={Reinforcement Learning},
  pages={441--470},
  year={2012},
  publisher={Springer}
}

@article{papoudakis2019dealing,
  title={Dealing with non-stationarity in multi-agent deep reinforcement learning},
  author={Papoudakis, Georgios and Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  journal={arXiv preprint arXiv:1906.04737},
  year={2019}
}

@article{rabin1999psychology,
  title={Psychology and economics},
  author={Rabin, Matthew},
  journal={Journal of Economic Literature},
  volume={36},
  number={1},
  pages={11--46},
  year={1998},
  publisher={American Economic Association}
}

@article{rashid2018qmix,
  title={QMIX: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={Proceedings of the 35th International Conference on Machine Learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the National Academy of Sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Academy of Sciences}
}

@article{sims2003implications,
  title={Implications of rational inattention},
  author={Sims, Christopher A},
  journal={Journal of Monetary Economics},
  volume={50},
  number={3},
  pages={665--690},
  year={2003},
  publisher={Elsevier}
}

@article{smith2000pathological,
  title={Pathological outcomes of observational learning},
  author={Smith, Lones and S{\o}rensen, Peter},
  journal={Econometrica},
  volume={68},
  number={2},
  pages={371--398},
  year={2000},
  publisher={Wiley Online Library}
}

@article{stahl1994experimental,
  title={Experimental evidence on players' models of other players},
  author={Stahl, Dale O and Wilson, Paul W},
  journal={Journal of Economic Behavior \& Organization},
  volume={25},
  number={3},
  pages={309--327},
  year={1994},
  publisher={Elsevier}
}

@article{sunehag2018value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2085--2087},
  year={2018},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S. and Barto, Andrew G.},
  year={2018},
  edition={2},
  publisher={MIT Press},
  address={Cambridge, MA}
}

@article{tampuu2017multiagent,
  title={Multiagent cooperation and competition with deep reinforcement learning},
  author={Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan and Vicente, Raul},
  journal={PloS One},
  volume={12},
  number={4},
  pages={e0172395},
  year={2017},
  publisher={Public Library of Science}
}

@article{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  journal={Proceedings of the 10th International Conference on Machine Learning},
  pages={330--337},
  year={1993},
  publisher={Morgan Kaufmann}
}

@article{wen2019probabilistic,
  title={Probabilistic recursive reasoning for multi-agent reinforcement learning},
  author={Wen, Ying and Yang, Yaodong and Luo, Rui and Wang, Jun and Pan, Wei},
  journal={Proceedings of the 7th International Conference on Learning Representations},
  year={2019}
}

@article{wicks2012algorithmcomputingstochasticallystable,
  title={An algorithm for computing stochastically stable distributions with applications to multiagent learning in repeated games},
  author={Wicks, J and Greenwald, A},
  journal={Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence},
  pages={623--632},
  year={2012},
  publisher={AUAI Press}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of Reinforcement Learning and Control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

@article{keller2020undiscounted,
  title={Undiscounted bandit games},
  author={Keller, Godfrey and Rady, Sven},
  journal={Games and Economic Behavior},
  volume={124},
  pages={43--61},
  year={2020},
  publisher={Elsevier}
}

@article{koopmans1960stationary,
  title={Stationary Ordinal Utility and Impatience},
  author={Koopmans, Tjalling C},
  journal={Econometrica},
  volume={28},
  number={2},
  pages={287--309},
  year={1960},
  publisher={JSTOR}
}

@book{stokey1989recursive,
  title={Recursive Methods in Economic Dynamics},
  author={Stokey, Nancy L and Lucas, Robert E and Prescott, Edward C},
  year={1989},
  publisher={Harvard University Press},
  address={Cambridge, MA}
}

@article{heidhues2015strategic,
title = {Strategic experimentation with private payoffs},
journal = {Journal of Economic Theory},
volume = {159},
pages = {531-551},
year = {2015},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2015.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0022053115001404},
author = {Paul Heidhues and Sven Rady and Philipp Strack},
keywords = {Strategic experimentation, Two-armed bandit, Bayesian learning, Information externality, Mediated communication, Cheap talk},
abstract = {We consider a game of strategic experimentation in which players face identical discrete-time bandit problems with a safe and a risky arm. In any period, the risky arm yields either a success or a failure, and the first success reveals the risky arm to dominate the safe one. When payoffs are public information, the ensuing free-rider problem is so severe that equilibrium experimentation ceases at the same threshold belief at which a single agent would stop, even if players can coordinate their actions through mediated communication. When payoffs are private information and the success probability on the risky arm is not too high, however, the socially optimal symmetric experimentation profile can be supported as a sequential equilibrium for sufficiently optimistic prior beliefs, even if players can only communicate via binary cheap-talk messages.}
}

@book{marl-book,
  author = {Stefano V. Albrecht and Filippos Christianos and Lukas Sch\"afer},
  title = {Multi-Agent Reinforcement Learning: Foundations and Modern Approaches},
  publisher = {MIT Press},
  year = {2024},
  url = {https://www.marl-book.com}
}

@article{yang2020overview,
  title={An overview of multi-agent reinforcement learning from game theoretical perspective},
  author={Yang, Yaodong and Wang, Jun},
  journal={arXiv preprint arXiv:2011.00583},
  year={2020}
}

@misc{huh2024multiagentreinforcementlearningcomprehensive,
      title={Multi-agent Reinforcement Learning: A Comprehensive Survey}, 
      author={Dom Huh and Prasant Mohapatra},
      year={2024},
      eprint={2312.10256},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2312.10256}, 
}

@misc{du2023reviewcooperationmultiagentlearning,
      title={A Review of Cooperation in Multi-agent Learning}, 
      author={Yali Du and Joel Z. Leibo and Usman Islam and Richard Willis and Peter Sunehag},
      year={2023},
      eprint={2312.05162},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2312.05162}, 
}

@misc{zhu2024surveymultiagentdeepreinforcement,
      title={A Survey of Multi-Agent Deep Reinforcement Learning with Communication}, 
      author={Changxi Zhu and Mehdi Dastani and Shihan Wang},
      year={2024},
      eprint={2203.08975},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2203.08975}, 
}

@inproceedings{meuleau1999pomdp,
  title={Policy Gradient Methods for Partially Observable {M}arkov Decision Processes},
  author={Meuleau, Nicolas and Peshkin, Leonid and Kim, Kee-Eung and Kaelbling, Leslie Pack},
  booktitle={Advances in Neural Information Processing Systems},
  volume={12},
  year={1999},
  publisher={MIT Press}
}

@article{aberdeen2002pg,
  title={Policy-Gradient Algorithms for Partially Observable {M}arkov Decision Processes},
  author={Aberdeen, Douglas and Baxter, Jonathan},
  journal={Advances in Neural Information Processing Systems},
  volume={15},
  year={2002},
  publisher={MIT Press}
}

@inproceedings{hausknecht2015drqn,
  title={Deep Recurrent {Q}-Learning for Partially Observable {MDPs}},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={AAAI Fall Symposium on Sequential Decision Making for Intelligent Agents},
  year={2015}
}

@inproceedings{peng2022belief,
  title={Belief-Grounded Networks for Accelerated Robot Learning under Partial Observability},
  author={Peng, Xue Bin and Guo, Ling and Zhang, Tianhe and Fei-Fei, Li and Abbeel, Pieter},
  booktitle={Conference on Robot Learning},
  year={2022}
}

@inproceedings{bhatnagar2009actor,
  title={Natural Actor-Critic Algorithms},
  author={Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
  booktitle={Advances in Neural Information Processing Systems},
  volume={21},
  year={2009}
}

@inproceedings{azizzadenesheli2018trust,
  title={Trust Region Policy Optimization of {POMDPs}},
  author={Azizzadenesheli, Kamyar and Brunskill, Emma and Anandkumar, Animashree},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{wunder2010value,
  title={On the Value of Information in Multi-agent Reinforcement Learning},
  author={Wunder, Michael and Littman, Michael L and Babes, Monica},
  journal={arXiv preprint arXiv:1011.0095},
  year={2010}
}

@inproceedings{buffet2007monte,
  title={Reinforcement Learning in Partially Observable Multi-agent Settings: {M}onte {C}arlo Exploration for {M}arkov Games},
  author={Buffet, Olivier and Dutech, Alain and Charpillet, Fran{\c{c}}ois},
  booktitle={Proceedings of the 6th International Joint Conference on Autonomous Agents and Multiagent Systems},
  pages={1--8},
  year={2007}
}

@article{hauskrecht2000value,
  title={Value-Function Approximations for Partially Observable {M}arkov Decision Processes},
  author={Hauskrecht, Milos},
  journal={Journal of Artificial Intelligence Research},
  volume={13},
  pages={33--94},
  year={2000}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  journal={Advances in Neural Information Processing Systems},
  volume={12},
  year={1999},
  publisher={MIT Press}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine Learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{jaakkola1994reinforcement,
  title={Reinforcement learning algorithm for partially observable {M}arkov decision problems},
  author={Jaakkola, Tommi and Singh, Satinder P and Jordan, Michael I},
  journal={Advances in Neural Information Processing Systems},
  volume={7},
  year={1994},
  publisher={MIT Press}
}


@inproceedings{meuleau1999learning,
  title={Learning to act in partially observable stochastic domains},
  author={Meuleau, Nicolas and Peshkin, Leonid and Kim, Kee-Eung and Kaelbling, Leslie Pack},
  booktitle={Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
  pages={99--116},
  year={1999}
}

@inproceedings{hausknecht2015deep,
  title={Deep recurrent {Q}-learning for partially observable {MDP}s},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={AAAI Fall Symposium on Sequential Decision Making for Intelligent Agents},
  year={2015}
}

@inproceedings{heess2015memory,
  title={Memory-based control with recurrent neural networks},
  author={Heess, Nicolas and Hunt, Jonathan J and Lillicrap, Timothy P and Silver, David},
  booktitle={NIPS Deep Reinforcement Learning Workshop},
  year={2015}
}

@book{pontryagin1962mathematical,
  title={The mathematical theory of optimal processes},
  author={Pontryagin, Lev Semenovich and Mishchenko, Evgenii Frolovich and Boltyanskii, Vladimir Grigorevich and Gamkrelidze, Revaz Valerianovich},
  year={1962},
  publisher={Wiley}
}

@book{bertsekas2005dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P},
  volume={1},
  number={3},
  year={2005},
  publisher={Athena Scientific}
}

@article{arapostathis1993discrete,
  title={Discrete-time adaptive control of systems with unknown noise statistics},
  author={Arapostathis, Aristotle and Marcus, Steven I},
  journal={IEEE Transactions on Automatic Control},
  volume={38},
  number={8},
  pages={1224--1231},
  year={1993},
  publisher={IEEE}
}

@inproceedings{li2017deep,
  title={Deep reinforcement learning for optimal control of space heating},
  author={Li, Borui and Raman, Radhakrishnan and Sastry, Shankar},
  booktitle={Building Simulation Conference},
  year={2017}
}

@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={International Conference on Machine Learning},
  pages={1467--1476},
  year={2018},
  organization={PMLR}
}

@misc{finn2017modelagnosticmetalearningfastadaptation,
      title={Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}, 
      author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
      year={2017},
      eprint={1703.03400},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.03400}, 
}

@misc{rajeswaran2019metalearningimplicitgradients,
      title={Meta-Learning with Implicit Gradients}, 
      author={Aravind Rajeswaran and Chelsea Finn and Sham Kakade and Sergey Levine},
      year={2019},
      eprint={1909.04630},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1909.04630}, 
}

@misc{haarnoja2018softactorcriticoffpolicymaximum,
      title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
      author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
      year={2018},
      eprint={1801.01290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1801.01290}, 
}

@misc{christodoulou2019softactorcriticdiscreteaction,
      title={Soft Actor-Critic for Discrete Action Settings}, 
      author={Petros Christodoulou},
      year={2019},
      eprint={1910.07207},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.07207}, 
}

@article{frederick2002time,
  title={Time discounting and time preference: A critical review},
  author={Frederick, Shane and Loewenstein, George and O'donoghue, Ted},
  journal={Journal of economic literature},
  volume={40},
  number={2},
  pages={351--401},
  year={2002},
  publisher={American Economic Association}
}

@inproceedings{Silver2014DeterministicPG,
  title={Deterministic Policy Gradient Algorithms},
  author={David Silver and Guy Lever and Nicolas Manfred Otto Heess and Thomas Degris and Daan Wierstra and Martin A. Riedmiller},
  booktitle={International Conference on Machine Learning},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:13928442}
}

@misc{lillicrap2019continuouscontroldeepreinforcement,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1509.02971}, 
}

@book{rudin1987real,
  title={Real and Complex Analysis},
  author={Rudin, W.},
  isbn={9780070542341},
  lccn={86000007},
  series={Higher Mathematics Series},
  url={https://books.google.de/books?id=Z_fuAAAAMAAJ},
  year={1987},
  publisher={McGraw-Hill Education}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{scarselli2009graph,
  title={The graph neural network model},
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks},
  volume={20},
  number={1},
  pages={61--80},
  year={2009},
  publisher={IEEE}
}

@article{kipf2017semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={International Conference on Learning Representations},
  year={2017}
}

@article{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Academy of Sciences}
}

@article{ndousse2021emergent,
  title={Emergent Social Learning via Multi-agent Reinforcement Learning},
  author={Ndousse, Kamal and Eck, Douglas and Levine, Sergey and Jaques, Natasha},
  journal={Proceedings of the 38th International Conference on Machine Learning},
  volume={139},
  pages={7991--8004},
  year={2021},
  publisher={PMLR}
}

@article{jaques2019social,
  title={Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  journal={Proceedings of the 36th International Conference on Machine Learning},
  volume={97},
  pages={3040--3049},
  year={2019},
  publisher={PMLR}
}

@article{omidshafiei2019learning,
  title={Learning to Teach in Cooperative Multiagent Reinforcement Learning},
  author={Omidshafiei, Shayegan and Kim, Dong-Ki and Liu, Miao and Tesauro, Gerald and Riemer, Matthew and Amato, Christopher and Campbell, Murray and How, Jonathan P},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={6128--6136},
  year={2019}
}

@article{rahmattalabi2020curriculum,
  title={Curriculum for Policy Learning in Multi-agent Settings},
  author={Rahmattalabi, Aida and Chung, Jen Jen and Colby, Mitchell and Tumer, Kagan},
  journal={Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1095--1103},
  year={2020}
}

@article{leibo2019autocurricula,
  title={Autocurricula and the Emergence of Innovation from Social Interaction: A Manifesto for Multi-Agent Intelligence Research},
  author={Leibo, Joel Z and Hughes, Edward and Lanctot, Marc and Graepel, Thore},
  journal={arXiv preprint arXiv:1903.00742},
  year={2019}
}

@article{baker2019emergent,
  title={Emergent Tool Use from Multi-Agent Autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2019}
}

@article{vezhnevets2020options,
  title={Options as responses: Grounding behavioural hierarchies in multi-agent reinforcement learning},
  author={Vezhnevets, Alexander and Wu, Yuhuai and Eckstein, Maria and Leblond, R{\'e}mi and Leibo, Joel Z},
  journal={Proceedings of the 37th International Conference on Machine Learning},
  volume={119},
  pages={9733--9742},
  year={2020},
  publisher={PMLR}
}

@article{rothschild1974two,
  title={Two-armed bandit theory of market pricing},
  author={Rothschild, Michael},
  journal={Journal of Economic Theory},
  volume={9},
  number={2},
  pages={185--202},
  year={1974},
  publisher={Elsevier}
}

@article{klein2011negatively,
  title={Negatively correlated bandits},
  author={Klein, Nicolas and Rady, Sven},
  journal={The Review of Economic Studies},
  volume={78},
  number={2},
  pages={693--732},
  year={2011},
  publisher={Oxford University Press}
}

@article{bonatti2017dynamic,
  title={Dynamic oligopoly with incomplete information},
  author={Bonatti, Alessandro and H{\"o}rner, Johannes},
  journal={The Review of Economic Studies},
  volume={84},
  number={2},
  pages={503--546},
  year={2017},
  publisher={Oxford University Press}
}

@article{yamamoto2019stochastic,
author = {Yamamoto, Yuichi},
title = {Stochastic games with hidden states},
journal = {Theoretical Economics},
volume = {14},
number = {3},
pages = {1115-1167},
keywords = {Stochastic game, hidden state, uniform connectedness, robust connectedness, random blocks, folk theorem, C72, C73},
doi = {https://doi.org/10.3982/TE3068},
url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/TE3068},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.3982/TE3068},
abstract = {This paper studies infinite-horizon stochastic games in which players observe actions and noisy public information about a hidden state each period. We find a general condition under which the feasible and individually rational payoff set is invariant to the initial prior about the state when players are patient. This result ensures that players can punish or reward their opponents via continuation payoffs in a flexible way. Then we prove the folk theorem, assuming that public randomization is available. The proof is constructive and uses the idea of random blocks to design an effective punishment mechanism.},
year = {2019}
}

}

@article{halac2017designing,
author = {Halac, Marina and Kartik, Navin and Liu, Qingmin},
title = {Contests for Experimentation},
journal = {Journal of Political Economy},
volume = {125},
number = {5},
pages = {1523-1569},
year = {2017},
doi = {10.1086/693040},

URL = { 
    
        https://doi.org/10.1086/693040
    
    

},
eprint = { 
    
        https://doi.org/10.1086/693040
    
    

}
,
    abstract = { We study contests for innovation with learning about the innovation’s feasibility and opponents’ outcomes. We characterize contests that maximize innovation when the designer chooses a prize-sharing scheme and a disclosure policy. A “public winner-takes-all” contest dominates public contests—where any success is immediately disclosed—with any other prize-sharing scheme as well as winner-takes-all contests with any other disclosure policy. Yet, jointly modifying prize sharing and disclosure can increase innovation. In a broad class of mechanisms, it is optimal to share the prize with disclosure following a certain number of successes; under simple conditions, a “hidden equal-sharing” contest is optimal. }
}

@article{kamenica2011bayesian,
Author = {Kamenica, Emir and Gentzkow, Matthew},
Title = {Bayesian Persuasion},
Journal = {American Economic Review},
Volume = {101},
Number = {6},
Year = {2011},
Month = {October},
Pages = {2590–2615},
DOI = {10.1257/aer.101.6.2590},
URL = {https://www.aeaweb.org/articles?id=10.1257/aer.101.6.2590}}

@article{bergemann2019information,
Author = {Bergemann, Dirk and Morris, Stephen},
Title = {Information Design: A Unified Perspective},
Journal = {Journal of Economic Literature},
Volume = {57},
Number = {1},
Year = {2019},
Month = {March},
Pages = {44–95},
DOI = {10.1257/jel.20181489},
URL = {https://www.aeaweb.org/articles?id=10.1257/jel.20181489}}

@article{che2018optimal,
  title={Optimal design for social learning},
  author={Che, Yeon-Koo and H{\"o}rner, Johannes},
  journal={Quarterly Journal of Economics},
  volume={133},
  number={2},
  pages={871--925},
  year={2018},
  publisher={Oxford University Press}
}

@article{avery1998multidimensional,
  title={Multidimensional uncertainty and herd behavior in financial markets},
  author={Avery, Christopher and Zemsky, Peter},
  journal={American Economic Review},
  volume={88},
  number={4},
  pages={724--748},
  year={1998},
  publisher={American Economic Association}
}

@inproceedings{zhang2015observational,
  title={Observational learning with information asymmetry: An experiment on social learning},
  author={Zhang, Haifeng and Vorobeychik, Yevgeniy},
  booktitle={Proceedings of the International Conference on Autonomous Agents and Multiagent Systems},
  pages={1189--1197},
  year={2015}
}

@article{gale1999learning,
  title={Learning, information, and social interactions},
  author={Gale, Douglas and Kariv, Shachar},
  journal={Games and Economic Behavior},
  volume={27},
  number={1},
  pages={102--134},
  year={1999},
  publisher={Elsevier}
}

@article{vives1993fast,
  title={How fast do rational agents learn?},
  author={Vives, Xavier},
  journal={The Review of Economic Studies},
  volume={60},
  number={2},
  pages={329--347},
  year={1993},
  publisher={Oxford University Press}
}

@article{Mossel_2013,
   title={Asymptotic learning on Bayesian social networks},
   volume={158},
   ISSN={1432-2064},
   url={http://dx.doi.org/10.1007/s00440-013-0479-y},
   DOI={10.1007/s00440-013-0479-y},
   number={1–2},
   journal={Probability Theory and Related Fields},
   publisher={Springer Science and Business Media LLC},
   author={Mossel, Elchanan and Sly, Allan and Tamuz, Omer},
   year={2013},
   month=feb, pages={127–157} }

@article{ellison1993rules,
title = {Rules of Thumb for Social Learning},
author = {Ellison, Glenn and Fudenberg, Drew},
year = {1993},
journal = {Journal of Political Economy},
volume = {101},
number = {4},
pages = {612-43},
abstract = {This paper studies agents who consider the experiences of their neighbors in deciding which of two technologies to use. The authors analyze two learning environments, one in which the same technology is optimal for all players and another in which each technology is better for some of them. In both environments, players use exogenously specified rules of thumb that ignore historical data but may incorporate a tendency to use the more popular technology. In some cases, these naive rules can lead to fairly efficient decisions in the long run but adjustment can be slow when a superior technology is first introduced. Copyright 1993 by University of Chicago Press.},
url = {https://EconPapers.repec.org/RePEc:ucp:jpolec:v:101:y:1993:i:4:p:612-43}
}


@article{bala1998learning,
  title={Learning from Neighbours},
  author={Bala, Venkatesh and Goyal, Sanjeev},
  journal={Review of Economic Studies},
  volume={65},
  number={3},
  pages={595--621},
  year={1998},
  publisher={Oxford University Press}
}

@inproceedings{Harel2014TheSO,
  title={The Speed of Social Learning},
  author={Matan Harel and Elchanan Mossel and Philipp Strack and Omer Tamuz},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:1483403}
}

@article{golub2012homophily,
 ISSN = {00335533, 15314650},
 URL = {http://www.jstor.org/stable/23251986},
 abstract = {We examine how the speed of learning and best-response processes depends on homophily: the tendency of agents to associate disproportionately with those having similar traits. When agents' beliefs or behaviors are developed by averaging what they see among their neighbors, then convergence to a consensus is slowed by the presence of homophily but is not influenced by network density (in contrast to other network processes that depend on shortest paths). In deriving these results, we propose a new, general measure of homophily based on the relative frequencies of interactions among different groups. An application to communication in a society before a vote shows how the time it takes for the vote to correctly aggregate information depends on the homophily and the initial information distribution.},
 author = {Benjamin Golub and Matthew O. Jackson},
 journal = {The Quarterly Journal of Economics},
 number = {3},
 pages = {1287--1338},
 publisher = {Oxford University Press},
 title = {HOW HOMOPHILY AFFECTS THE SPEED OF LEARNING AND BEST-RESPONSE DYNAMICS},
 urldate = {2025-05-14},
 volume = {127},
 year = {2012}
}

@article{guarino2013social,
Author = {Guarino, Antonio and Jehiel, Philippe},
Title = {Social Learning with Coarse Inference},
Journal = {American Economic Journal: Microeconomics},
Volume = {5},
Number = {1},
Year = {2013},
Month = {February},
Pages = {147–74},
DOI = {10.1257/mic.5.1.147},
URL = {https://www.aeaweb.org/articles?id=10.1257/mic.5.1.147}}


@article{Jadbabaie2013InformationHA,
  title={Information Heterogeneity and the Speed of Learning in Social Networks},
  author={Ali Jadbabaie and Pooya Molavi and Alireza Tahbaz-Salehi},
  journal={Writing Technologies eJournal},
  year={2013},
  url={https://api.semanticscholar.org/CorpusID:17438004}
}

@article{rosenberg2009informational,
title = {Informational externalities and emergence of consensus},
journal = {Games and Economic Behavior},
volume = {66},
number = {2},
pages = {979-994},
year = {2009},
note = {Special Section In Honor of David Gale},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2008.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0899825608001772},
author = {Dinah Rosenberg and Eilon Solan and Nicolas Vieille},
abstract = {We study a general model of dynamic games with purely informational externalities. We prove that eventually all motives for experimentation disappear, and provide the exact rate at which experimentation decays. We also provide tight conditions under which players eventually reach a consensus. These results imply extensions of many known results in the literature of social learning and getting to agreement.}
}


@article{dasaratha2020learning,
  title={Learning from persuasive messages},
  author={Dasaratha, Krishna and Golub, Benjamin and Hak, Nir},
  journal={Journal of Political Economy},
  volume={128},
  number={4},
  pages={1401--1447},
  year={2020},
  publisher={University of Chicago Press}
}

@article{bhattacharya2013strategic,
  title={Strategic information revelation when experts compete to influence},
  author={Bhattacharya, Sourav and Mukherjee, Arijit},
  journal={The RAND Journal of Economics},
  volume={44},
  number={3},
  pages={522--544},
  year={2013},
  URL = {http://www.jstor.org/stable/43186430},
 abstract = {We consider a persuasion game between a decision-maker and a set of experts. Each expert is identified by two parameters: (i) "quality" or his likelihood of observing the state (i.e., learning what the best decision is) and (ii) "agenda" or the preferred decision that is independent of the state. An informed expert may feign ignorance but cannot misreport. We offer a general characterization of the equilibrium. From the decision-maker's standpoint, (a) higher quality is not necessarily better, (b) extreme agendas are always preferred, and (c) the optimal panel may involve experts with identical (rather than conflicting) agendas.},
 author = {Sourav Bhattacharya and Arijit Mukherjee},
 journal = {The RAND Journal of Economics},
 number = {3},
 pages = {522--544},
 publisher = {[RAND Corporation, Wiley]},
 title = {Strategic information revelation when experts compete to influence},
 urldate = {2025-05-14},
 volume = {44},
 year = {2013}
}


@article{ARIELI2019185,
title = {Private Bayesian persuasion},
journal = {Journal of Economic Theory},
volume = {182},
pages = {185-217},
year = {2019},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2019.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0022053118302217},
author = {Itai Arieli and Yakov Babichenko},
keywords = {Bayesian persuasion, Supermodular utility, Submodular utility},
abstract = {We consider a multi-receiver Bayesian persuasion problem where an informed sender tries to persuade a group of receivers to adopt a certain product. The sender is allowed to commit to a signaling policy where she sends a private signal to every receiver. The utility of the sender is a function of the subset of adopters and the realized state. We first consider a setting with a binary state space and no payoff externalities among receivers. We characterize an optimal signaling policy and the maximal revenue to the sender for two different types of utility functions: supermodular, and anonymous submodular. In particular, for supermodular utilities we show that the optimal policy correlates positive recommendation to adopt the product as much as possible. We generalize these results to the case of a nonbinary state space. The result for supermodular utilities is generalized to the case where receivers have payoff externalities. We also provide a necessary and sufficient condition under which public and conditionally independent signaling policies are optimal.}
}

@misc{iqbal2019actorattentioncriticmultiagentreinforcementlearning,
      title={Actor-Attention-Critic for Multi-Agent Reinforcement Learning}, 
      author={Shariq Iqbal and Fei Sha},
      year={2019},
      eprint={1810.02912},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1810.02912}, 
}

@misc{vandeven2024continuallearningcatastrophicforgetting,
      title={Continual Learning and Catastrophic Forgetting}, 
      author={Gido M. van de Ven and Nicholas Soures and Dhireesha Kudithipudi},
      year={2024},
      eprint={2403.05175},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.05175}, 
}

@article{52862b84-7c34-3186-8b28-6af4806272c3,
 ISSN = {00804630},
 URL = {http://www.jstor.org/stable/97883},
 abstract = {It is shown that a certain differential form depending on the values of the parameters in a law of chance is invariant for all transformations of the parameters when the law is differentiable with regard to all parameters. For laws containing a location and a scale parameter a form with a somewhat restricted type of invariance is found even when the law is not everywhere differentiable with regard to the parameters. This form has the properties required to give a general rule for stating the prior probability in a large class of estimation problems.},
 author = {Harold Jeffreys},
 journal = {Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences},
 number = {1007},
 pages = {453--461},
 publisher = {The Royal Society},
 title = {An Invariant Form for the Prior Probability in Estimation Problems},
 urldate = {2025-05-12},
 volume = {186},
 year = {1946}
}

@article{weibull1997evolutionary,
  title={Evolutionary game theory},
  author={Weibull, J{\"o}rgen W},
  year={1997},
  publisher={MIT press}
}

@article{tuyls2004evolutionary,
 ISSN = {00397857, 15730964},
 URL = {http://www.jstor.org/stable/20118420},
 abstract = {In this paper we revise Reinforcement Learning and adaptiveness in Multi-Agent Systems from an Evolutionary Game Theoretic perspective. More precisely we show there is a triangular relation between the fields of Multi-Agent Systems, Reinforcement Learning and Evolutionary Game Theory. We illustrate how these new insights can contribute to a better understanding of learning in MAS and to new improved learning algorithms. All three fields are introduced in a self-contained manner. Each relation is discussed in detail with the necessary background information to understand it, along with major references to relevant work.},
 author = {Karl Tuyls and Ann Nowe and Tom Lenaerts and Bernard Manderick},
 journal = {Synthese},
 number = {2},
 pages = {297--330},
 publisher = {Springer},
 title = {An Evolutionary Game Theoretic Perspective on Learning in Multi-Agent Systems},
 urldate = {2025-05-14},
 volume = {139},
 year = {2004}
}


@article{leibo2017multi,
  title={Multi-agent reinforcement learning in sequential social dilemmas},
  author={Leibo, Joel Z and Zambaldi, Vinicius and Lanctot, Marc and Marecki, Janusz and Graepel, Thore},
  journal={Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
  pages={464--473},
  year={2017}
}

@article{silver2016mastering,
  added-at = {2017-05-07T12:43:52.000+0200},
  author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  biburl = {https://www.bibsonomy.org/bibtex/265a1c9455003f91c61b725aa46f466a6/hotho},
  interhash = {5892845b739023cd7f42e7cce276d935},
  intrahash = {65a1c9455003f91c61b725aa46f466a6},
  journal = {Nature},
  keywords = {alphago deep learning wj2017},
  number = 7587,
  pages = {484--489},
  publisher = {Nature Publishing Group},
  timestamp = {2017-05-07T12:43:52.000+0200},
  title = {Mastering the game of Go with deep neural networks and tree search},
  volume = 529,
  year = 2016
}
@misc{baker2020emergentreciprocityteamformation,
      title={Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences}, 
      author={Bowen Baker},
      year={2020},
      eprint={2011.05373},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2011.05373}, 
}

@misc{openai2019dota2largescale,
      title={Dota 2 with Large Scale Deep Reinforcement Learning}, 
      author={OpenAI},
      year={2019},
      eprint={1912.06680},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.06680}, 
}
@article{demarzo2003persuasion,
    author = {DeMarzo, Peter M. and Vayanos, Dimitri and Zwiebel, Jeffrey},
    title = {Persuasion Bias, Social Influence, and Unidimensional Opinions*},
    journal = {The Quarterly Journal of Economics},
    volume = {118},
    number = {3},
    pages = {909-968},
    year = {2003},
    month = {08},
    abstract = {We propose a boundedly rational model of opinion formation in which individuals are subject to persuasion bias; that is, they fail to account for possible repetition in the information they receive. We show that persuasion bias implies the phenomenon of social influence, whereby one's influence on group opinions depends not only on accuracy, but also on how well-connected one is in the social network that determines communication. Persuasion bias also implies the phenomenon of unidimensional opinions; that is, individuals' opinions over a multidimensional set of issues converge to a single "left-right" spectrum. We explore the implications of our model in several natural settings, including political science and marketing, and we obtain a number of novel empirical implications.},
    issn = {0033-5533},
    doi = {10.1162/00335530360698469},
    url = {https://doi.org/10.1162/00335530360698469},
    eprint = {https://academic.oup.com/qje/article-pdf/118/3/909/5472964/118-3-909.pdf},
}

@article{higham2001algorithmic,
  title={An algorithmic introduction to numerical simulation of stochastic differential equations},
  author={Higham, Desmond J},
  journal={SIAM Review},
  volume={43},
  number={3},
  pages={525--546},
  year={2001},
  publisher={SIAM}
}

@book{kloeden1992numerical,
  title={Numerical Solution of Stochastic Differential Equations},
  author={Kloeden, Peter E and Platen, Eckhard},
  year={1992},
  publisher={Springer-Verlag, Berlin}
}

@book{platen1999introduction,
  title={An Introduction to Numerical Methods for Stochastic Differential Equations},
  author={Platen, Eckhard},
  year={1999},
  publisher={Springer-Verlag, Berlin}
}

@article{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart J},
  journal={Proceedings of the 16th International Conference on Machine Learning},
  pages={278--287},
  year={1999},
  publisher={Morgan Kaufmann}
}

@book{applebaum2009levy,
  title={L{\'e}vy Processes and Stochastic Calculus},
  author={Applebaum, David},
  year={2009},
  publisher={Cambridge University Press},
  series={Cambridge Studies in Advanced Mathematics},
  volume={116},
  edition={2}
}

@book{kushner2001numerical,
  title={Numerical Methods for Controlled Stochastic Delay Systems},
  author={Kushner, Harold J},
  year={2001},
  publisher={Springer Science \& Business Media}
}

@book{sato1999levy,
  title={L{\'e}vy Processes and Infinitely Divisible Distributions},
  author={Sato, Ken-iti},
  year={1999},
  publisher={Cambridge University Press},
  series={Cambridge Studies in Advanced Mathematics},
  volume={68}
}

@book{protter2005stochastic,
  title={Stochastic Integration and Differential Equations},
  author={Protter, Philip E.},
  year={2005},
  publisher={Springer},
  series={Stochastic Modelling and Applied Probability},
  volume={21},
  edition={2}
}


@article{dia2013error,
  title={Error Bounds for Small Jumps of L{\'e}vy Processes},
  author={Dia, E. H. A.},
  journal={Advances in Applied Probability},
  volume={45},
  number={1},
  pages={86--105},
  year={2013},
  publisher={Applied Probability Trust},
  doi={10.1239/aap/1363354104}
}

@book{platen2010numerical,
  title={Numerical solution of stochastic differential equations with jumps in finance},
  author={Platen, Eckhard and Bruti-Liberati, Nicola},
  volume={64},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@article{higham2005numerical,
title = "Numerical methods for nonlinear stochastic differential equations with jumps",
abstract = "We present and analyse two implicit methods for Ito stochastic differential equations (SDEs) with Poisson-driven jumps. The first method, SSBE, is a split-step extension of the backward Euler method. The second method, CSSBE, arises from the introduction of a compensated, martingale, form of the Poisson process. We show that both methods are amenable to rigorous analysis when a one-sided Lipschitz condition, rather than a more restrictive global Lipschitz condition, holds for the drift. Our analysis covers strong convergence and nonlinear stability. We prove that both methods give strong convergence when the drift coefficient is one-sided Lipschitz and the diffusion and jump coefficients are globally Lipschitz. On the way to proving these results, we show that a compensated form of the Euler-Maruyama method converges strongly when the SDE coefficients satisfy a local Lipschitz condition and the pth moment of the exact and numerical solution are bounded for some p>2. Under our assumptions, both SSBE and CSSBE give well-defined, unique solutions for sufficiently small stepsizes, and SSBE has the advantage that the restriction is independent of the jump intensity. We also study the ability of the methods to reproduce exponential mean-square stability in the case where the drift has a negative one-sided Lipschitz constant. This work extends the deterministic nonlinear stability theory in numerical analysis. We find that SSBE preserves stability under a stepsize constraint that is independent of the initial data. CSSBE satisfies an even stronger condition, and gives a generalization of B-stability. Finally, we specialize to a linear test problem and show that CSSBE has a natural extension of deterministic A-stability. The difference in stability properties of the SSBE and CSSBE methods emphasizes that the addition of a jump term has a significant effect that cannot be deduced directly from the non-jump literature.",
keywords = "A-stability, B-stability, backward Euler, compensated Poisson process, Euler-Maruyama, exponential stability, global Lipschitz, implicit method, jump-diffusion, mean-square stability, nonlinear stability, one-sided Lipschitz, Poisson process, strong convergence",
author = "D.J. Higham and Kloeden, {Peter E.}",
year = "2005",
month = jul,
doi = "10.1007/s00211-005-0611-8",
language = "English",
volume = "101",
pages = "101--119",
journal = "Numerische Mathematik",
issn = "0029-599X",
publisher = "Springer New York",
number = "1",
}

@misc{zenke2017continuallearningsynapticintelligence,
      title={Continual Learning Through Synaptic Intelligence}, 
      author={Friedemann Zenke and Ben Poole and Surya Ganguli},
      year={2017},
      eprint={1703.04200},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.04200}, 
}

@inproceedings{caccia2021new,
  title={New Insights on Reducing Abrupt Representation Change in Online Continual Learning},
  author={Caccia, Lucas and Aljundi, Rahaf and Asadi, Nader and Tuytelaars, Tinne and Pineau, Joelle and Belilovsky, Eugene},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{sarfraz2023error,
  title={Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning},
  author={Sarfraz, Fahad and Arani, Elahe and Zonooz, Bahram},
  booktitle={International Conference on Learning Representations},
  year={2023}
}