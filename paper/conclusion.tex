This thesis bridges economic social learning theory and multi-agent reinforcement learning by developing Partially Observable Active Markov Games (POAMGs) and the POLARIS algorithm. Our framework addresses fundamental challenges in modeling adaptive behavior under partial observability, demonstrating how computational approaches can complement traditional economic theory while providing new insights into complex social learning dynamics. The integration of these traditionally separate domains opens new research directions that neither field could pursue independently, establishing a foundation for understanding how rational agents learn and adapt in environments characterized by both environmental uncertainty and strategic interdependence.


Our work makes four interconnected contributions that advance both theoretical understanding and computational capabilities. First, we developed the POAMG framework, extending Active Markov Games to partially observable settings where agents reason about both environmental uncertainty and evolving strategies of others. This formalization captures the essential tension between exploration for private information and exploitation of social information that characterizes real-world learning scenarios.
Second, we provided theoretical analysis of convergence and equilibrium properties in POAMGs, establishing conditions for stochastic stability and deriving policy gradient theorems for average and discounted reward objectives. We extended the framework to continuous-time dynamics through stochastic differential equations and revealed how traditional game-theoretic equilibrium concepts relate to active equilibrium when agents account for others' learning processes. These theoretical foundations provide rigorous guarantees for algorithm convergence while preserving the strategic structure inherent in social learning problems.
Third, we introduced POLARIS, combining belief processing through Transformer models, inference learning via variational methods, and reinforcement learning optimization. This enables agents to develop sophisticated strategies accounting for both environmental partial observability and strategic adaptation by other agents. The algorithm's modular architecture allows for principled handling of belief updates, strategic reasoning, and policy optimization in a unified framework.
Fourth, we validated our framework through applications to strategic experimentation and learning without experimentation, demonstrating how our approach captures dynamic role assignment, information generation and exploitation, and the emergence of learning barriers and coordination benefits. These applications illustrate the framework's versatility in addressing diverse social learning phenomena while maintaining computational tractability.

Our experimental analysis reveals that dynamic role assignment is a robust organizing principle of multi-agent learning systems. Across both scenarios, agents naturally differentiate into complementary roles enhancing collective information processing. This finding has profound implications for understanding how efficient information aggregation emerges spontaneously in social systems without central coordination.
Our results show that free-riding behavior does not lead to predicted inefficiencies for the whole population—performance of some agents in larger networks substantially exceeds autarky levels. This challenges conventional wisdom about free-riding and suggests that network effects can compensate for individual incentive problems in ways not captured by traditional theoretical models.
The computational approach illuminates fundamental tension between theoretical and practical approaches: while economic models envision agents developing ex ante strategies optimal across all states, reinforcement learning agents converge to ex post strategies optimized for specific realized states. This tension reveals limitations in directly applying computational methods to test theoretical predictions while suggesting opportunities for more realistic behavioral models that account for cognitive constraints and learning dynamics.

Our methodological contributions extend beyond the specific applications studied. The two-staged analysis methodology provides systematic approaches for extracting insights from multi-agent learning dynamics despite catastrophic forgetting in neural networks. The discretization approach for continuous-time economic models, treating Lévy processes through Euler-Maruyama schemes and mapping continuous decisions to discrete action probabilities, provides a template for computational implementation while preserving essential incentive structures. We constructed an observed reward function that enables reinforcement learning in environments without direct reward signals and developed a specialized transformer loss function for Lévy process observations. Our implementation incorporates Graph Neural Networks with temporal and spatial attention mechanisms that capture both network topology and temporal dependencies in multi-agent interactions. Furthermore, we introduce off-equilibrium asymmetric analysis methods that move beyond the symmetric equilibria analysis in economic theory, allowing for heterogeneous agent behaviors and asymmetric strategy convergence patterns.

The technical innovations in belief representation and inference learning represent significant advances in handling partial observability in multi-agent settings. Our approach to combining variational inference with transformer architectures for belief processing enables agents to maintain sophisticated internal models of both environmental states and other agents' strategies. The integration of these components with policy gradient methods creates a principled framework for learning in complex strategic environments that has applications beyond social learning scenarios.

Despite these advances, our approach faces important limitations that highlight directions for future research. Catastrophic forgetting prevents direct measurement of equilibrium strategies that economic theory predicts, requiring alternative analytical approaches. Computational complexity limits analysis to small networks and short time horizons, potentially missing asymptotic behaviors that theoretical models emphasize. The discretization of continuous-time models, while necessary for computational tractability, may introduce artifacts that affect the correspondence between theoretical predictions and computational results.

Several promising avenues emerge from this work. First, developing sophisticated continual learning techniques specifically for social learning environments could address catastrophic forgetting limitations through architectures maintaining separate policy components for different states. Second, scaling our framework to larger networks and longer horizons would enable validation of asymptotic results and investigation of emergent phenomena in complex social systems. Third, extending to dynamic environments where underlying states change over time would broaden applicability to real-world scenarios characterized by non-stationarity. Fourth, investigating optimal information structures and network topologies could inform platform and institutional design. Fifth, applying our framework to diverse social learning phenomena such as herding behavior, social teaching and mentoring, imitation cascades, and collective decision-making could illuminate the mechanisms underlying these important social processes and inform interventions to promote beneficial outcomes.

This thesis demonstrates the value of interdisciplinary approaches bridging economic theory and computational methods. By preserving theoretical rigor while leveraging modern machine learning techniques, we gain insights into complex social phenomena that neither approach could achieve alone. The framework provides a template for future work that seeks to combine formal theoretical analysis with sophisticated computational tools.
The insights have implications for financial markets, organizational learning, online social networks, and collaborative scientific endeavors. Dynamic role assignment suggests that effective social learning systems naturally develop specialized roles enhancing collective information processing, providing guidance for platform design and institutional arrangements. Understanding how learning barriers emerge and can be overcome informs the design of systems that promote effective knowledge sharing and collective decision-making.
Our POAMG framework and POLARIS algorithm contribute to multi-agent reinforcement learning literature by providing principled approaches for handling partial observability and strategic adaptation. The techniques for belief processing, inference learning, and integrated optimization may prove valuable for other applications requiring sophisticated multi-agent coordination under uncertainty. The theoretical foundations we establish create opportunities for developing new algorithms and analyzing their properties in strategic settings.
Looking forward, the convergence of economic theory and artificial intelligence presents exciting opportunities for advancing understanding of social learning and strategic behavior. This thesis provides theoretical foundations and computational tools for future researchers to illuminate the rich dynamics of social learning in complex environments. The integration of these domains opens new possibilities for addressing challenges in artificial intelligence, economics, and social sciences more broadly. While significant progress has been made in bridging these domains, much work remains to fully realize the potential of this integration, with the ultimate goal of better understanding how intelligent agents can learn from each other to make better decisions in an uncertain world. The journey toward this understanding promises to yield insights that will transform both our theoretical understanding and our practical ability to design systems that harness collective intelligence for solving complex problems.
